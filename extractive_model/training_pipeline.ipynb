{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e0c289d-e898-4fff-a909-605364d2991d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-07T17:53:49.840008Z",
     "iopub.status.busy": "2025-05-07T17:53:49.839569Z",
     "iopub.status.idle": "2025-05-07T17:53:58.771574Z",
     "shell.execute_reply": "2025-05-07T17:53:58.770630Z",
     "shell.execute_reply.started": "2025-05-07T17:53:49.839971Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForQuestionAnswering were not initialized from the model checkpoint at ../../shared/models/ru-e5-large and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForQuestionAnswering,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    default_data_collator\n",
    ")\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ[\"JAX_PLATFORM_NAME\"] = \"cpu\"\n",
    "os.environ[\"XLA_PYTHON_CLIENT_PREALLOCATE\"] = \"false\"\n",
    "os.environ[\"XLA_PYTHON_CLIENT_ALLOCATOR\"] = \"platform\"\n",
    "\n",
    "# Set device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "PRETRAINED = \"../../shared/models/ru-e5-large\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(PRETRAINED)\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(PRETRAINED).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83036c52-b0c6-4555-be8d-8cad7086b41c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-07T17:53:58.778493Z",
     "iopub.status.busy": "2025-05-07T17:53:58.778113Z",
     "iopub.status.idle": "2025-05-07T17:53:58.780674Z",
     "shell.execute_reply": "2025-05-07T17:53:58.780216Z",
     "shell.execute_reply.started": "2025-05-07T17:53:58.778477Z"
    }
   },
   "outputs": [],
   "source": [
    "# import jax\n",
    "# print(jax.__file__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aec6b142-f840-4c32-bca3-52efc981bc95",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-07T17:53:58.781532Z",
     "iopub.status.busy": "2025-05-07T17:53:58.781280Z",
     "iopub.status.idle": "2025-05-07T17:53:58.784075Z",
     "shell.execute_reply": "2025-05-07T17:53:58.783586Z",
     "shell.execute_reply.started": "2025-05-07T17:53:58.781518Z"
    }
   },
   "outputs": [],
   "source": [
    "# !pip show -f jax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75fbaa4b-f7e4-4403-a418-07b834eb5bf8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-07T17:54:57.645003Z",
     "iopub.status.busy": "2025-05-07T17:54:57.644769Z",
     "iopub.status.idle": "2025-05-07T17:54:58.345597Z",
     "shell.execute_reply": "2025-05-07T17:54:58.344691Z",
     "shell.execute_reply.started": "2025-05-07T17:54:57.644986Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load your CSV\n",
    "df = pd.read_csv(\"extractive_summ_data.csv\")\n",
    "\n",
    "# Convert DataFrame to HuggingFace Dataset\n",
    "dataset = Dataset.from_pandas(df)\n",
    "\n",
    "# Split into train and validation\n",
    "train_val = dataset.train_test_split(test_size=0.15, seed=42)\n",
    "train_dataset = train_val[\"train\"]\n",
    "val_dataset = train_val[\"test\"]\n",
    "\n",
    "# Create DatasetDict\n",
    "dataset_dict = DatasetDict({\n",
    "    \"train\": train_dataset,\n",
    "    \"validation\": val_dataset\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5cfd3df9-096e-4a70-83f7-6e0706d98aad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-07T17:54:59.720536Z",
     "iopub.status.busy": "2025-05-07T17:54:59.720308Z",
     "iopub.status.idle": "2025-05-07T17:54:59.732198Z",
     "shell.execute_reply": "2025-05-07T17:54:59.731276Z",
     "shell.execute_reply.started": "2025-05-07T17:54:59.720520Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Unnamed: 0': 2847,\n",
       " 'id': '243c1e75-9e07-4893-a977-80e9c7457ac5',\n",
       " 'context': 'X5 Retail опубликовала отчетность без особых сюрпризов, рынок отреагировал сдержанно. Тем не менее, аналитики продолжают следить за ситуацией, особенно в контексте валютных колебаний и изменения сырьевых цен.\\nНа фоне ожиданий по ставке ЦБ, многие участники рынка заняли выжидательную позицию.\\nГазпром опубликовала отчетность без особых сюрпризов, рынок отреагировал сдержанно. Тем не менее, аналитики продолжают следить за ситуацией, особенно в контексте валютных колебаний и изменения сырьевых цен.\\nРубль стабилизировался после волатильной недели, но долгосрочные перспективы остаются неясными.\\nOzon в последнее время демонстрирует неоднозначную динамику. С одной стороны, финансовые показатели за квартал превзошли ожидания аналитиков, с другой — сохраняется высокая волатильность на фоне глобальных рисков. Пока инвесторы сохраняют осторожность, несмотря на краткосрочные сигналы роста.\\nTotalEnergies опубликовала отчетность без особых сюрпризов, рынок отреагировал сдержанно. Тем не менее, аналитики продолжают следить за ситуацией, особенно в контексте валютных колебаний и изменения сырьевых цен.',\n",
       " 'question': 'Ozon',\n",
       " 'answer': 'Ozon в последнее время демонстрирует неоднозначную динамику. С одной стороны, финансовые показатели за квартал превзошли ожидания аналитиков, с другой — сохраняется высокая волатильность на фоне глобальных рисков. Пока инвесторы сохраняют осторожность, несмотря на краткосрочные сигналы роста.',\n",
       " 'answer_start': 596,\n",
       " 'answer_end': 889}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ddd0e4d-72bd-427c-a65f-5b757640ba72",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-06T19:31:26.778417Z",
     "iopub.status.busy": "2025-05-06T19:31:26.777991Z",
     "iopub.status.idle": "2025-05-06T19:31:26.783595Z",
     "shell.execute_reply": "2025-05-06T19:31:26.782646Z",
     "shell.execute_reply.started": "2025-05-06T19:31:26.778378Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'context', 'question', 'answer', 'answer_start', 'answer_end', '__index_level_0__'],\n",
       "        num_rows: 14517\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'context', 'question', 'answer', 'answer_start', 'answer_end', '__index_level_0__'],\n",
       "        num_rows: 2562\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c3901296-c125-44c7-bfac-e6b0b1528618",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-06T19:31:27.112139Z",
     "iopub.status.busy": "2025-05-06T19:31:27.111750Z",
     "iopub.status.idle": "2025-05-06T19:31:43.054580Z",
     "shell.execute_reply": "2025-05-06T19:31:43.053450Z",
     "shell.execute_reply.started": "2025-05-06T19:31:27.112106Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04e125a382a64142830162a8d64e1d8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing datasets:   0%|          | 0/14517 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad69e9e5de114522a759ecd5934cc69e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing datasets:   0%|          | 0/2562 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb50739eeb4e4c728231e6f9b7b9c79b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2562 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def prepare_features(examples):\n",
    "    tokenized = tokenizer(\n",
    "        examples[\"question\"],\n",
    "        examples[\"context\"],\n",
    "        max_length=512,\n",
    "        truncation=\"only_second\",\n",
    "        padding=\"max_length\",\n",
    "        return_offsets_mapping=True\n",
    "    )\n",
    "\n",
    "    # Save a copy of offset mapping for later (metrics)\n",
    "    offset_mappings = tokenized[\"offset_mapping\"]\n",
    "\n",
    "    # Compute start/end token positions\n",
    "    start_positions = []\n",
    "    end_positions = []\n",
    "\n",
    "    for i in range(len(examples[\"answer\"])):\n",
    "        offsets = offset_mappings[i]\n",
    "        sequence_ids = tokenized.sequence_ids(i)\n",
    "        input_ids = tokenized[\"input_ids\"][i]\n",
    "        cls_index = input_ids.index(tokenizer.cls_token_id)\n",
    "\n",
    "        answer_start = examples[\"answer_start\"][i]\n",
    "        answer_end = examples[\"answer_end\"][i]\n",
    "\n",
    "        # Find context token span\n",
    "        context_start = next(i for i, sid in enumerate(sequence_ids) if sid == 1)\n",
    "        context_end = max(i for i, sid in enumerate(sequence_ids) if sid == 1)\n",
    "\n",
    "        if not (answer_start >= offsets[context_start][0] and answer_end <= offsets[context_end][1]):\n",
    "            start_positions.append(cls_index)\n",
    "            end_positions.append(cls_index)\n",
    "        else:\n",
    "            start = context_start\n",
    "            while start < len(offsets) and offsets[start][0] <= answer_start:\n",
    "                start += 1\n",
    "            end = context_end\n",
    "            while end >= 0 and offsets[end][1] >= answer_end:\n",
    "                end -= 1\n",
    "            start_positions.append(start - 1)\n",
    "            end_positions.append(end + 1)\n",
    "\n",
    "    tokenized[\"start_positions\"] = start_positions\n",
    "    tokenized[\"end_positions\"] = end_positions\n",
    "\n",
    "    # Keep offset_mapping only for eval\n",
    "    tokenized[\"offset_mapping\"] = offset_mappings\n",
    "    tokenized[\"example_id\"] = examples[\"id\"]\n",
    "    return tokenized\n",
    "\n",
    "\n",
    "# Store offset mappings for validation set separately\n",
    "tokenized_datasets = dataset_dict.map(\n",
    "    prepare_features,\n",
    "    batched=True,\n",
    "    remove_columns=dataset_dict[\"train\"].column_names,\n",
    "    desc=\"Tokenizing datasets\"\n",
    ")\n",
    "\n",
    "\n",
    "# Save tokenized validation data\n",
    "tokenized_validation = dataset_dict[\"validation\"].map(\n",
    "    prepare_features,\n",
    "    batched=True,\n",
    "    remove_columns=dataset_dict[\"validation\"].column_names\n",
    ")\n",
    "validation_features = tokenized_validation\n",
    "\n",
    "offset_mappings = validation_features[\"offset_mapping\"]\n",
    "example_ids = validation_features[\"example_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ab91b8fc-af45-4237-902c-d2822dc733cc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-06T19:31:49.783770Z",
     "iopub.status.busy": "2025-05-06T19:31:49.783529Z",
     "iopub.status.idle": "2025-05-06T19:31:49.789308Z",
     "shell.execute_reply": "2025-05-06T19:31:49.788511Z",
     "shell.execute_reply.started": "2025-05-06T19:31:49.783754Z"
    }
   },
   "outputs": [],
   "source": [
    "def show_predictions(index):\n",
    "    encoded = tokenized_datasets[\"validation\"][index]\n",
    "    decoded = tokenizer.decode(encoded[\"input_ids\"], skip_special_tokens=False)\n",
    "\n",
    "    print(\"Encoded input:\", decoded)\n",
    "\n",
    "    tokens = tokenizer.convert_ids_to_tokens(encoded[\"input_ids\"])\n",
    "    print(\"Tokens:\", tokens)\n",
    "\n",
    "    start_pos = encoded[\"start_positions\"]\n",
    "    end_pos = encoded[\"end_positions\"]\n",
    "    print(f\"Answer span: {tokens[start_pos]} ... {tokens[end_pos]}\")\n",
    "    print(f\"Answer text: {' '.join(tokens[start_pos:end_pos+1])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ec3088a3-4a11-4c6a-aea9-31b49c0cebe0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-06T19:31:50.315826Z",
     "iopub.status.busy": "2025-05-06T19:31:50.315596Z",
     "iopub.status.idle": "2025-05-06T19:31:50.320593Z",
     "shell.execute_reply": "2025-05-06T19:31:50.319506Z",
     "shell.execute_reply.started": "2025-05-06T19:31:50.315807Z"
    }
   },
   "outputs": [],
   "source": [
    "# show_predictions(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1f3c52e7-3cf2-402d-b81e-cd23a944f2c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-06T19:31:50.810973Z",
     "iopub.status.busy": "2025-05-06T19:31:50.810569Z",
     "iopub.status.idle": "2025-05-06T19:31:50.922045Z",
     "shell.execute_reply": "2025-05-06T19:31:50.921120Z",
     "shell.execute_reply.started": "2025-05-06T19:31:50.810941Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import evaluate\n",
    "from collections import defaultdict\n",
    "\n",
    "squad_metric = evaluate.load(\"squad\")\n",
    "\n",
    "from transformers import EvalPrediction\n",
    "cached_features = tokenized_datasets[\"validation\"]\n",
    "cached_raw_dataset = val_dataset\n",
    "\n",
    "\n",
    "def compute_metrics(eval_prediction):\n",
    "    start_logits, end_logits = eval_prediction.predictions\n",
    "    predictions = []\n",
    "    references = []\n",
    "\n",
    "    for i, feature in enumerate(cached_features):\n",
    "        offset_mapping = feature[\"offset_mapping\"]\n",
    "        context = cached_raw_dataset[i][\"context\"]\n",
    "        answer = cached_raw_dataset[i][\"answer\"]\n",
    "        answer_start = cached_raw_dataset[i][\"answer_start\"]\n",
    "\n",
    "        start_idx = int(np.argmax(start_logits[i]))\n",
    "        end_idx = int(np.argmax(end_logits[i]))\n",
    "\n",
    "        if (\n",
    "            start_idx >= len(offset_mapping)\n",
    "            or end_idx >= len(offset_mapping)\n",
    "            or offset_mapping[start_idx] is None\n",
    "            or offset_mapping[end_idx] is None\n",
    "            or end_idx < start_idx\n",
    "        ):\n",
    "            pred_text = \"\"\n",
    "        else:\n",
    "            start_char = offset_mapping[start_idx][0]\n",
    "            end_char = offset_mapping[end_idx][1]\n",
    "            pred_text = context[start_char:end_char]\n",
    "\n",
    "        predictions.append({\"id\": feature[\"example_id\"], \"prediction_text\": pred_text})\n",
    "        references.append({\n",
    "            \"id\": feature[\"example_id\"],\n",
    "            \"answers\": {\n",
    "                \"text\": [answer],\n",
    "                \"answer_start\": [answer_start]\n",
    "            }\n",
    "        })\n",
    "\n",
    "    return squad_metric.compute(predictions=predictions, references=references)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ca25caf4-72af-431d-ac4c-17c2f6dc2c19",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-06T19:31:51.544717Z",
     "iopub.status.busy": "2025-05-06T19:31:51.544501Z",
     "iopub.status.idle": "2025-05-06T19:31:51.549031Z",
     "shell.execute_reply": "2025-05-06T19:31:51.548008Z",
     "shell.execute_reply.started": "2025-05-06T19:31:51.544702Z"
    }
   },
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "compute_metrics_with_data = partial(\n",
    "    compute_metrics,\n",
    "    features=validation_features,\n",
    "    raw_dataset=val_dataset\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "810bd7cf-3953-4364-88eb-7797292e6f13",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-06T19:31:52.309842Z",
     "iopub.status.busy": "2025-05-06T19:31:52.309451Z",
     "iopub.status.idle": "2025-05-06T19:31:52.317045Z",
     "shell.execute_reply": "2025-05-06T19:31:52.316083Z",
     "shell.execute_reply.started": "2025-05-06T19:31:52.309810Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'attention_mask', 'offset_mapping', 'start_positions', 'end_positions', 'example_id'],\n",
       "    num_rows: 2562\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets[\"validation\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "81ba8b87-3087-48e6-aae7-e92c359782f2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-06T19:31:53.696866Z",
     "iopub.status.busy": "2025-05-06T19:31:53.696476Z",
     "iopub.status.idle": "2025-05-06T19:31:53.814940Z",
     "shell.execute_reply": "2025-05-06T19:31:53.813568Z",
     "shell.execute_reply.started": "2025-05-06T19:31:53.696834Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/transformers/training_args.py:1611: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_1275719/1307781823.py:20: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"steps\",\n",
    "    learning_rate=3e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=4,\n",
    "    num_train_epochs=10,\n",
    "    weight_decay=0.01,\n",
    "    # save_strategy=\"steps\",\n",
    "    # load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    report_to=\"none\",\n",
    "    logging_strategy=\"epoch\",\n",
    "    eval_steps=20,\n",
    "    eval_accumulation_steps=5\n",
    ")\n",
    "\n",
    "# Create Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=default_data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0f4687ef-7f32-401e-aa52-1bad9a6dff82",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-06T19:31:54.757105Z",
     "iopub.status.busy": "2025-05-06T19:31:54.756527Z",
     "iopub.status.idle": "2025-05-06T19:51:35.838697Z",
     "shell.execute_reply": "2025-05-06T19:51:35.837336Z",
     "shell.execute_reply.started": "2025-05-06T19:31:54.757070Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='278' max='9080' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 278/9080 19:37 < 10:25:47, 0.23 it/s, Epoch 0.31/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Exact Match</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.958750</td>\n",
       "      <td>12.841530</td>\n",
       "      <td>43.877486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.732234</td>\n",
       "      <td>63.817330</td>\n",
       "      <td>74.692714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.247621</td>\n",
       "      <td>93.754879</td>\n",
       "      <td>96.297110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.099337</td>\n",
       "      <td>95.979703</td>\n",
       "      <td>97.106317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.048475</td>\n",
       "      <td>98.360656</td>\n",
       "      <td>99.268762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.034709</td>\n",
       "      <td>98.946136</td>\n",
       "      <td>99.461170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.015240</td>\n",
       "      <td>99.141296</td>\n",
       "      <td>99.687807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.011656</td>\n",
       "      <td>99.648712</td>\n",
       "      <td>99.816743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.011971</td>\n",
       "      <td>99.570648</td>\n",
       "      <td>99.748795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.006470</td>\n",
       "      <td>99.609680</td>\n",
       "      <td>99.925223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.003826</td>\n",
       "      <td>99.882904</td>\n",
       "      <td>99.934421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.007221</td>\n",
       "      <td>99.687744</td>\n",
       "      <td>99.848258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.003236</td>\n",
       "      <td>99.921936</td>\n",
       "      <td>99.934331</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/transformers/trainer.py:2245\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2243\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2244\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2245\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2246\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2247\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2248\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2249\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2250\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/transformers/trainer.py:2561\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2555\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[1;32m   2556\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_step(model, inputs, num_items_in_batch)\n\u001b[1;32m   2558\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2559\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2560\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[0;32m-> 2561\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misinf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtr_loss_step\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   2562\u001b[0m ):\n\u001b[1;32m   2563\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2564\u001b[0m     tr_loss \u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m+\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n\u001b[1;32m   2565\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c4c4340a-b2f8-413e-9420-c3dd12765e2c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-06T19:53:52.957762Z",
     "iopub.status.busy": "2025-05-06T19:53:52.957527Z",
     "iopub.status.idle": "2025-05-06T19:53:58.211228Z",
     "shell.execute_reply": "2025-05-06T19:53:58.210590Z",
     "shell.execute_reply.started": "2025-05-06T19:53:52.957745Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./qa_model_russian/tokenizer_config.json',\n",
       " './qa_model_russian/special_tokens_map.json',\n",
       " './qa_model_russian/sentencepiece.bpe.model',\n",
       " './qa_model_russian/added_tokens.json',\n",
       " './qa_model_russian/tokenizer.json')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(\"./qa_model_russian\")\n",
    "tokenizer.save_pretrained(\"./qa_model_russian\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b47568-16fd-4cff-9472-ba9594a27579",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d710bda3-633e-458c-a10c-232937bcf9f0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-06T20:37:50.179567Z",
     "iopub.status.busy": "2025-05-06T20:37:50.179332Z",
     "iopub.status.idle": "2025-05-06T20:37:51.142967Z",
     "shell.execute_reply": "2025-05-06T20:37:51.142367Z",
     "shell.execute_reply.started": "2025-05-06T20:37:50.179552Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Answer: Яндекс (+4,7%), Сбер (+2,8%) и Т-Технологии (+3,1%), то есть большая часть краткосрочных фаворитов аналитиков БКС.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
    "import torch\n",
    "\n",
    "# Load model and tokenizer\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model_path = \"./qa_model_russian\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(model_path).to(device)\n",
    "\n",
    "# Question\n",
    "question = \"Яндекс\"\n",
    "\n",
    "# Initial context text\n",
    "context = \"\"\"\n",
    "В Госдепе США сообщили, что Вашингтон отказывается от роли посредника в диалоге между Россией и Украиной, но будет продолжать работать над достижением мира, однако разрешение ситуации зависит от «конкретных действий» со стороны Москвы и Киева.  \n",
    "\n",
    "Не добавляет и позитива динамика цены на нефть. Попытки развить вчерашний отскок не реализовались, и котировки опустились ниже $61 за баррель.\n",
    "\n",
    "Акции газовых компаний — Газпрома и НОВАТЭКа — сегодня среди аутсайдеров. \n",
    "\n",
    "Газпром представил в среду сильные финансовые результаты за 2024 г. Расчетный дивиденд 30,3 руб. Главный вопрос — вернется ли корпорация к распределению прибыли впервые с 2022 г. Выплаты не заложены в бюджет, что добавляет неопределенности вкупе к геополитической повестке в целом.  \n",
    "\n",
    "Бумаги НОВАТЭКа несут потери четвертый день подряд. Ближайшая поддержка — 200-дневная скользящая средняя на 1121 руб. Кроме общерыночного пессимизма, давление оказывает и снижение цен на нефть. Финансовые показатели компании зависят, в частности, от цен на черное золото (компания продает продукты переработки газового конденсата, а долгосрочные СПГ-контракты привязаны к котировкам Brent).\n",
    "\n",
    "Бумаги Полюса пытаются отскочить после семи дней падения. Цены на золото в пятницу вышли в умеренный плюс после коррекционного снижения от исторических максимумов. Также поддержку оказывает и резкое снижение рубля. Для выхода на уверенную траекторию роста нужна поддержка со стороны цен на базовый актив.\n",
    "\n",
    "Акции ВТБ во второй половине дня сократили дневные потери. Поддержку бумагам оказывает дивидендный фактор. Набсовет банка рекомендовал выплатить дивиденды за 2024 г. в размере 25,58 руб. на одну акцию. Текущая дивидендная доходность — около 26,3%. «Дивидендный сюрприз» стал драйвером роста бумаг в понедельник. Сдерживает оптимизм вероятность проведения допэмиссии для пополнения капитала, но ее параметры пока неизвестны.\n",
    "\n",
    "Префы Транснефти смотрятся сильнее коллег по сектору. Здесь тоже в фокусе дивиденды за 2024 г. После выхода отчета за прошлый год, мы оцениваем их размер в 190 руб. на акцию (дивидендная доходность 15%). Кроме того, доходы компании не зависят от ценовой конъюнктуры на рынке нефти, где баррель Brent за месяц подешевел на 15%.\n",
    "\n",
    "Обычка БСП — в небольшом минусе и смотрится лучше большинства представителей Индекса МосБиржи. Акции на текущей неделе переписали свои исторические максимумы — теперь это 416,97 руб., но уже в понедельник ждем серьезного падения. Причина — бумаги 5 мая очистятся от финальных дивидендов за 2024 г.  Выплаты составят 29,72 руб. на обычку, что предполагает текущую дивидендную доходность на уровне 7,3%. С учетом налогов на старте следующе неделе они могут потерять 6,4%.\n",
    "\n",
    "Акции Nanduq (бывшая Qiwi) сегодня подскочили на 21%. Поводом для резкого скачка вверх могло стать уведомление ликвидатора Киви-Банка акционерам о наличии и праве акционеров на получение имущества, оставшегося после завершения расчетов с кредиторами.\n",
    "\"\"\"\n",
    "\n",
    "context = \"\"\"\n",
    "Главное\n",
    "• Индекс МосБиржи вырос почти на 3% во вторник после пятидневного снижения.\n",
    "\n",
    "• Цены на нефть вчера провоцировали продажи, а сегодня поддерживают покупателей, прибавляя 4%.\n",
    "\n",
    "• Акции Газпрома в фокусе.\n",
    "\n",
    "• Лидеры: Россети Северо-Запад (+7,5%), БСП-ап (+3,8%), ПИК (+5,2%), Русснефть (+5%).\n",
    "\n",
    "• Аутсайдеры: NanduQ (-1,4%), Башнефть-ао (-0,8%), Россети Урал (-0,3%), ВИ.ру (-0,2%).\n",
    "\n",
    "В деталях\n",
    "Рынок акций сегодня восстанавливается после 10%-ого снижения от максимумов апреля. Внушительный отскок, который перекрывает всю просадку понедельника выглядит позитивно, хотя до поддержки растущего тренда последних месяцев в районе 2650 индекс не дошел. \n",
    "\n",
    "При достаточно активном движении обороты лишь приближаются к средним — сказывается торговый период между длинными выходными. В составе индекса наторговали на 82 млрд руб. \n",
    "\n",
    "Никуда не исчезли и геополитические причины сдерживающие активность. Агентство Reuters сообщило, что ЕС предлагает включить в 17-й пакет санкций против России более 100 судов, связанных с российским «теневым флотом», и еще 60 физлиц и юрлиц.\n",
    "\n",
    "Внешний фон поддержал отскок цен на нефть. Котировки Brent вчера опускались ниже $59 за баррель, а сегодня вернулись к $62,5. Здесь могли сказаться вышеназванные угрозы ЕС против РФ, возвращение к торгам трейдеров крупнейшего импортера нефти —Китая после длинных выходных, банальный спекулятивный отскок.\n",
    "\n",
    "На прошлой неделе в фокусе инвесторов были акции Газпрома ввиду ожидавшегося отчета, который оказался неплохим, хотя аналитики сдержанно оценивают перспективы высоких дивидендов. Сегодня бумага остается на первой строчке по оборотам на фоне ряда новостей.\n",
    "\n",
    "Во-первых, в начале вечерней сессии глава Минфина Антон Силуанов подтвердил, что в бюджет 2025 г. не заложены дивиденды Газпрома. Но также он отметил, что задействовать специальные меры, в том числе налоговые, для повышения доходов бюджета в этом году не планируется. Откат на этих новостях был скоротечным. \n",
    "\n",
    "Во вторых, Еврокомиссия представила «дорожную карту» отказа от российских энергоресурсов, но и это не сильно расстроило инвесторов, с учетом того, что ЕС еще в 2022 г. озвучил подобные планы. В то же время, помощник президента РФ Юрий Ушаков заявил, что президент РФ Владимир Путин и председатель КНР Си Цзиньпин 8 мая обсудят широкий круг вопросов, включая конфликт на Украине, энергетику. Относительно последней инвесторов интересует, конечно, вопрос «Силы Сибири-2». Акции Газпрома выросли на 2,5% на основных торгах.\n",
    "\n",
    "Среди лидеров сегодня были акции ПИК, Самолета, ВК, Системы, то есть компаний чувствительных к высоким процентным ставкам, которые и падали с опережением. Отдельно здесь стоит сказать о ВК, акционеры которой одобрили допэмиссию. ВК таким образом планирует снизить долговую нагрузку. Размер выпуска — до 115 млрд руб. Цена акции при допэмиссии — 324,9 руб., на 33% выше текущей. Аналитики БКС учли в своей модели допэмиссию и сохраняют нейтральный взгляд на бумагу с целевой ценой 300 руб.\n",
    "\n",
    "Несмотря на отскок цен на нефть, более сильную динамику сегодня показали не Роснефть (+1,9%), ЛУКОЙЛ (+1,4%) и Татнефть (+1,3%), а Яндекс (+4,7%), Сбер (+2,8%) и Т-Технологии (+3,1%), то есть большая часть краткосрочных фаворитов аналитиков БКС.\n",
    "\n",
    "Обоснованный рост продолжается в акциях Полюса. Котировки золота смогли вчера отскочить от минимумов с середины апреля и уже превысили отметку $3400. \n",
    "\n",
    "Несколько настораживает, что сегодняшний оптимизм на рынке акций не был поддержан столько же активной динамикой ОФЗ. RGBI прибавил лишь 0,06%. Завтра Минфин проведет аукцион по размещению облигаций 26233, а Росстат представит данные по недельной инфляции.\n",
    "\n",
    "Рубль пока по-прежнему не спешит снижаться. Официальный курс доллара опустился ниже 81.\n",
    "\"\"\"\n",
    "\n",
    "# Split the context by newlines into paragraphs\n",
    "paragraphs = context.strip().split(\"\\n\")\n",
    "\n",
    "# Run QA on each paragraph and select the best\n",
    "best_answer = \"\"\n",
    "best_score = float('-inf')\n",
    "\n",
    "for paragraph in paragraphs:\n",
    "    inputs = tokenizer(question, paragraph, return_tensors=\"pt\", truncation=True).to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "    start_scores = outputs.start_logits\n",
    "    end_scores = outputs.end_logits\n",
    "\n",
    "    start_idx = torch.argmax(start_scores)\n",
    "    end_idx = torch.argmax(end_scores) + 1\n",
    "\n",
    "    answer_tokens = inputs[\"input_ids\"][0][start_idx:end_idx]\n",
    "    answer = tokenizer.decode(answer_tokens, skip_special_tokens=True)\n",
    "\n",
    "    score = start_scores[0][start_idx] + end_scores[0][end_idx - 1]\n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_answer = answer\n",
    "\n",
    "print(f\"Best Answer: {best_answer}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ddee70b-7f43-4fce-889e-ecf73f170adf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
