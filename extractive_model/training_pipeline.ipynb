{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e0c289d-e898-4fff-a909-605364d2991d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-07T17:53:49.840008Z",
     "iopub.status.busy": "2025-05-07T17:53:49.839569Z",
     "iopub.status.idle": "2025-05-07T17:53:58.771574Z",
     "shell.execute_reply": "2025-05-07T17:53:58.770630Z",
     "shell.execute_reply.started": "2025-05-07T17:53:49.839971Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForQuestionAnswering were not initialized from the model checkpoint at ../../shared/models/ru-e5-large and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForQuestionAnswering,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    default_data_collator\n",
    ")\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ[\"JAX_PLATFORM_NAME\"] = \"cpu\"\n",
    "os.environ[\"XLA_PYTHON_CLIENT_PREALLOCATE\"] = \"false\"\n",
    "os.environ[\"XLA_PYTHON_CLIENT_ALLOCATOR\"] = \"platform\"\n",
    "\n",
    "# Set device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "PRETRAINED = \"../../shared/models/ru-e5-large\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(PRETRAINED)\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(PRETRAINED).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83036c52-b0c6-4555-be8d-8cad7086b41c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-07T17:53:58.778493Z",
     "iopub.status.busy": "2025-05-07T17:53:58.778113Z",
     "iopub.status.idle": "2025-05-07T17:53:58.780674Z",
     "shell.execute_reply": "2025-05-07T17:53:58.780216Z",
     "shell.execute_reply.started": "2025-05-07T17:53:58.778477Z"
    }
   },
   "outputs": [],
   "source": [
    "# import jax\n",
    "# print(jax.__file__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aec6b142-f840-4c32-bca3-52efc981bc95",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-07T17:53:58.781532Z",
     "iopub.status.busy": "2025-05-07T17:53:58.781280Z",
     "iopub.status.idle": "2025-05-07T17:53:58.784075Z",
     "shell.execute_reply": "2025-05-07T17:53:58.783586Z",
     "shell.execute_reply.started": "2025-05-07T17:53:58.781518Z"
    }
   },
   "outputs": [],
   "source": [
    "# !pip show -f jax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75fbaa4b-f7e4-4403-a418-07b834eb5bf8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-07T17:54:57.645003Z",
     "iopub.status.busy": "2025-05-07T17:54:57.644769Z",
     "iopub.status.idle": "2025-05-07T17:54:58.345597Z",
     "shell.execute_reply": "2025-05-07T17:54:58.344691Z",
     "shell.execute_reply.started": "2025-05-07T17:54:57.644986Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load your CSV\n",
    "df = pd.read_csv(\"extractive_summ_data.csv\")\n",
    "\n",
    "# Convert DataFrame to HuggingFace Dataset\n",
    "dataset = Dataset.from_pandas(df)\n",
    "\n",
    "# Split into train and validation\n",
    "train_val = dataset.train_test_split(test_size=0.15, seed=42)\n",
    "train_dataset = train_val[\"train\"]\n",
    "val_dataset = train_val[\"test\"]\n",
    "\n",
    "# Create DatasetDict\n",
    "dataset_dict = DatasetDict({\n",
    "    \"train\": train_dataset,\n",
    "    \"validation\": val_dataset\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5cfd3df9-096e-4a70-83f7-6e0706d98aad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-07T17:54:59.720536Z",
     "iopub.status.busy": "2025-05-07T17:54:59.720308Z",
     "iopub.status.idle": "2025-05-07T17:54:59.732198Z",
     "shell.execute_reply": "2025-05-07T17:54:59.731276Z",
     "shell.execute_reply.started": "2025-05-07T17:54:59.720520Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Unnamed: 0': 2847,\n",
       " 'id': '243c1e75-9e07-4893-a977-80e9c7457ac5',\n",
       " 'context': 'X5 Retail –æ–ø—É–±–ª–∏–∫–æ–≤–∞–ª–∞ –æ—Ç—á–µ—Ç–Ω–æ—Å—Ç—å –±–µ–∑ –æ—Å–æ–±—ã—Ö —Å—é—Ä–ø—Ä–∏–∑–æ–≤, —Ä—ã–Ω–æ–∫ –æ—Ç—Ä–µ–∞–≥–∏—Ä–æ–≤–∞–ª —Å–¥–µ—Ä–∂–∞–Ω–Ω–æ. –¢–µ–º –Ω–µ –º–µ–Ω–µ–µ, –∞–Ω–∞–ª–∏—Ç–∏–∫–∏ –ø—Ä–æ–¥–æ–ª–∂–∞—é—Ç —Å–ª–µ–¥–∏—Ç—å –∑–∞ —Å–∏—Ç—É–∞—Ü–∏–µ–π, –æ—Å–æ–±–µ–Ω–Ω–æ –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ –≤–∞–ª—é—Ç–Ω—ã—Ö –∫–æ–ª–µ–±–∞–Ω–∏–π –∏ –∏–∑–º–µ–Ω–µ–Ω–∏—è —Å—ã—Ä—å–µ–≤—ã—Ö —Ü–µ–Ω.\\n–ù–∞ —Ñ–æ–Ω–µ –æ–∂–∏–¥–∞–Ω–∏–π –ø–æ —Å—Ç–∞–≤–∫–µ –¶–ë, –º–Ω–æ–≥–∏–µ —É—á–∞—Å—Ç–Ω–∏–∫–∏ —Ä—ã–Ω–∫–∞ –∑–∞–Ω—è–ª–∏ –≤—ã–∂–∏–¥–∞—Ç–µ–ª—å–Ω—É—é –ø–æ–∑–∏—Ü–∏—é.\\n–ì–∞–∑–ø—Ä–æ–º –æ–ø—É–±–ª–∏–∫–æ–≤–∞–ª–∞ –æ—Ç—á–µ—Ç–Ω–æ—Å—Ç—å –±–µ–∑ –æ—Å–æ–±—ã—Ö —Å—é—Ä–ø—Ä–∏–∑–æ–≤, —Ä—ã–Ω–æ–∫ –æ—Ç—Ä–µ–∞–≥–∏—Ä–æ–≤–∞–ª —Å–¥–µ—Ä–∂–∞–Ω–Ω–æ. –¢–µ–º –Ω–µ –º–µ–Ω–µ–µ, –∞–Ω–∞–ª–∏—Ç–∏–∫–∏ –ø—Ä–æ–¥–æ–ª–∂–∞—é—Ç —Å–ª–µ–¥–∏—Ç—å –∑–∞ —Å–∏—Ç—É–∞—Ü–∏–µ–π, –æ—Å–æ–±–µ–Ω–Ω–æ –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ –≤–∞–ª—é—Ç–Ω—ã—Ö –∫–æ–ª–µ–±–∞–Ω–∏–π –∏ –∏–∑–º–µ–Ω–µ–Ω–∏—è —Å—ã—Ä—å–µ–≤—ã—Ö —Ü–µ–Ω.\\n–†—É–±–ª—å —Å—Ç–∞–±–∏–ª–∏–∑–∏—Ä–æ–≤–∞–ª—Å—è –ø–æ—Å–ª–µ –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ–π –Ω–µ–¥–µ–ª–∏, –Ω–æ –¥–æ–ª–≥–æ—Å—Ä–æ—á–Ω—ã–µ –ø–µ—Ä—Å–ø–µ–∫—Ç–∏–≤—ã –æ—Å—Ç–∞—é—Ç—Å—è –Ω–µ—è—Å–Ω—ã–º–∏.\\nOzon –≤ –ø–æ—Å–ª–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–µ—Ç –Ω–µ–æ–¥–Ω–æ–∑–Ω–∞—á–Ω—É—é –¥–∏–Ω–∞–º–∏–∫—É. –° –æ–¥–Ω–æ–π —Å—Ç–æ—Ä–æ–Ω—ã, —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏ –∑–∞ –∫–≤–∞—Ä—Ç–∞–ª –ø—Ä–µ–≤–∑–æ—à–ª–∏ –æ–∂–∏–¥–∞–Ω–∏—è –∞–Ω–∞–ª–∏—Ç–∏–∫–æ–≤, —Å –¥—Ä—É–≥–æ–π ‚Äî —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç—Å—è –≤—ã—Å–æ–∫–∞—è –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å –Ω–∞ —Ñ–æ–Ω–µ –≥–ª–æ–±–∞–ª—å–Ω—ã—Ö —Ä–∏—Å–∫–æ–≤. –ü–æ–∫–∞ –∏–Ω–≤–µ—Å—Ç–æ—Ä—ã —Å–æ—Ö—Ä–∞–Ω—è—é—Ç –æ—Å—Ç–æ—Ä–æ–∂–Ω–æ—Å—Ç—å, –Ω–µ—Å–º–æ—Ç—Ä—è –Ω–∞ –∫—Ä–∞—Ç–∫–æ—Å—Ä–æ—á–Ω—ã–µ —Å–∏–≥–Ω–∞–ª—ã —Ä–æ—Å—Ç–∞.\\nTotalEnergies –æ–ø—É–±–ª–∏–∫–æ–≤–∞–ª–∞ –æ—Ç—á–µ—Ç–Ω–æ—Å—Ç—å –±–µ–∑ –æ—Å–æ–±—ã—Ö —Å—é—Ä–ø—Ä–∏–∑–æ–≤, —Ä—ã–Ω–æ–∫ –æ—Ç—Ä–µ–∞–≥–∏—Ä–æ–≤–∞–ª —Å–¥–µ—Ä–∂–∞–Ω–Ω–æ. –¢–µ–º –Ω–µ –º–µ–Ω–µ–µ, –∞–Ω–∞–ª–∏—Ç–∏–∫–∏ –ø—Ä–æ–¥–æ–ª–∂–∞—é—Ç —Å–ª–µ–¥–∏—Ç—å –∑–∞ —Å–∏—Ç—É–∞—Ü–∏–µ–π, –æ—Å–æ–±–µ–Ω–Ω–æ –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ –≤–∞–ª—é—Ç–Ω—ã—Ö –∫–æ–ª–µ–±–∞–Ω–∏–π –∏ –∏–∑–º–µ–Ω–µ–Ω–∏—è —Å—ã—Ä—å–µ–≤—ã—Ö —Ü–µ–Ω.',\n",
       " 'question': 'Ozon',\n",
       " 'answer': 'Ozon –≤ –ø–æ—Å–ª–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–µ—Ç –Ω–µ–æ–¥–Ω–æ–∑–Ω–∞—á–Ω—É—é –¥–∏–Ω–∞–º–∏–∫—É. –° –æ–¥–Ω–æ–π —Å—Ç–æ—Ä–æ–Ω—ã, —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏ –∑–∞ –∫–≤–∞—Ä—Ç–∞–ª –ø—Ä–µ–≤–∑–æ—à–ª–∏ –æ–∂–∏–¥–∞–Ω–∏—è –∞–Ω–∞–ª–∏—Ç–∏–∫–æ–≤, —Å –¥—Ä—É–≥–æ–π ‚Äî —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç—Å—è –≤—ã—Å–æ–∫–∞—è –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å –Ω–∞ —Ñ–æ–Ω–µ –≥–ª–æ–±–∞–ª—å–Ω—ã—Ö —Ä–∏—Å–∫–æ–≤. –ü–æ–∫–∞ –∏–Ω–≤–µ—Å—Ç–æ—Ä—ã —Å–æ—Ö—Ä–∞–Ω—è—é—Ç –æ—Å—Ç–æ—Ä–æ–∂–Ω–æ—Å—Ç—å, –Ω–µ—Å–º–æ—Ç—Ä—è –Ω–∞ –∫—Ä–∞—Ç–∫–æ—Å—Ä–æ—á–Ω—ã–µ —Å–∏–≥–Ω–∞–ª—ã —Ä–æ—Å—Ç–∞.',\n",
       " 'answer_start': 596,\n",
       " 'answer_end': 889}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ddd0e4d-72bd-427c-a65f-5b757640ba72",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-06T19:31:26.778417Z",
     "iopub.status.busy": "2025-05-06T19:31:26.777991Z",
     "iopub.status.idle": "2025-05-06T19:31:26.783595Z",
     "shell.execute_reply": "2025-05-06T19:31:26.782646Z",
     "shell.execute_reply.started": "2025-05-06T19:31:26.778378Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'context', 'question', 'answer', 'answer_start', 'answer_end', '__index_level_0__'],\n",
       "        num_rows: 14517\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'context', 'question', 'answer', 'answer_start', 'answer_end', '__index_level_0__'],\n",
       "        num_rows: 2562\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c3901296-c125-44c7-bfac-e6b0b1528618",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-06T19:31:27.112139Z",
     "iopub.status.busy": "2025-05-06T19:31:27.111750Z",
     "iopub.status.idle": "2025-05-06T19:31:43.054580Z",
     "shell.execute_reply": "2025-05-06T19:31:43.053450Z",
     "shell.execute_reply.started": "2025-05-06T19:31:27.112106Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04e125a382a64142830162a8d64e1d8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing datasets:   0%|          | 0/14517 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad69e9e5de114522a759ecd5934cc69e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing datasets:   0%|          | 0/2562 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb50739eeb4e4c728231e6f9b7b9c79b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2562 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def prepare_features(examples):\n",
    "    tokenized = tokenizer(\n",
    "        examples[\"question\"],\n",
    "        examples[\"context\"],\n",
    "        max_length=512,\n",
    "        truncation=\"only_second\",\n",
    "        padding=\"max_length\",\n",
    "        return_offsets_mapping=True\n",
    "    )\n",
    "\n",
    "    # Save a copy of offset mapping for later (metrics)\n",
    "    offset_mappings = tokenized[\"offset_mapping\"]\n",
    "\n",
    "    # Compute start/end token positions\n",
    "    start_positions = []\n",
    "    end_positions = []\n",
    "\n",
    "    for i in range(len(examples[\"answer\"])):\n",
    "        offsets = offset_mappings[i]\n",
    "        sequence_ids = tokenized.sequence_ids(i)\n",
    "        input_ids = tokenized[\"input_ids\"][i]\n",
    "        cls_index = input_ids.index(tokenizer.cls_token_id)\n",
    "\n",
    "        answer_start = examples[\"answer_start\"][i]\n",
    "        answer_end = examples[\"answer_end\"][i]\n",
    "\n",
    "        # Find context token span\n",
    "        context_start = next(i for i, sid in enumerate(sequence_ids) if sid == 1)\n",
    "        context_end = max(i for i, sid in enumerate(sequence_ids) if sid == 1)\n",
    "\n",
    "        if not (answer_start >= offsets[context_start][0] and answer_end <= offsets[context_end][1]):\n",
    "            start_positions.append(cls_index)\n",
    "            end_positions.append(cls_index)\n",
    "        else:\n",
    "            start = context_start\n",
    "            while start < len(offsets) and offsets[start][0] <= answer_start:\n",
    "                start += 1\n",
    "            end = context_end\n",
    "            while end >= 0 and offsets[end][1] >= answer_end:\n",
    "                end -= 1\n",
    "            start_positions.append(start - 1)\n",
    "            end_positions.append(end + 1)\n",
    "\n",
    "    tokenized[\"start_positions\"] = start_positions\n",
    "    tokenized[\"end_positions\"] = end_positions\n",
    "\n",
    "    # Keep offset_mapping only for eval\n",
    "    tokenized[\"offset_mapping\"] = offset_mappings\n",
    "    tokenized[\"example_id\"] = examples[\"id\"]\n",
    "    return tokenized\n",
    "\n",
    "\n",
    "# Store offset mappings for validation set separately\n",
    "tokenized_datasets = dataset_dict.map(\n",
    "    prepare_features,\n",
    "    batched=True,\n",
    "    remove_columns=dataset_dict[\"train\"].column_names,\n",
    "    desc=\"Tokenizing datasets\"\n",
    ")\n",
    "\n",
    "\n",
    "# Save tokenized validation data\n",
    "tokenized_validation = dataset_dict[\"validation\"].map(\n",
    "    prepare_features,\n",
    "    batched=True,\n",
    "    remove_columns=dataset_dict[\"validation\"].column_names\n",
    ")\n",
    "validation_features = tokenized_validation\n",
    "\n",
    "offset_mappings = validation_features[\"offset_mapping\"]\n",
    "example_ids = validation_features[\"example_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ab91b8fc-af45-4237-902c-d2822dc733cc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-06T19:31:49.783770Z",
     "iopub.status.busy": "2025-05-06T19:31:49.783529Z",
     "iopub.status.idle": "2025-05-06T19:31:49.789308Z",
     "shell.execute_reply": "2025-05-06T19:31:49.788511Z",
     "shell.execute_reply.started": "2025-05-06T19:31:49.783754Z"
    }
   },
   "outputs": [],
   "source": [
    "def show_predictions(index):\n",
    "    encoded = tokenized_datasets[\"validation\"][index]\n",
    "    decoded = tokenizer.decode(encoded[\"input_ids\"], skip_special_tokens=False)\n",
    "\n",
    "    print(\"Encoded input:\", decoded)\n",
    "\n",
    "    tokens = tokenizer.convert_ids_to_tokens(encoded[\"input_ids\"])\n",
    "    print(\"Tokens:\", tokens)\n",
    "\n",
    "    start_pos = encoded[\"start_positions\"]\n",
    "    end_pos = encoded[\"end_positions\"]\n",
    "    print(f\"Answer span: {tokens[start_pos]} ... {tokens[end_pos]}\")\n",
    "    print(f\"Answer text: {' '.join(tokens[start_pos:end_pos+1])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ec3088a3-4a11-4c6a-aea9-31b49c0cebe0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-06T19:31:50.315826Z",
     "iopub.status.busy": "2025-05-06T19:31:50.315596Z",
     "iopub.status.idle": "2025-05-06T19:31:50.320593Z",
     "shell.execute_reply": "2025-05-06T19:31:50.319506Z",
     "shell.execute_reply.started": "2025-05-06T19:31:50.315807Z"
    }
   },
   "outputs": [],
   "source": [
    "# show_predictions(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1f3c52e7-3cf2-402d-b81e-cd23a944f2c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-06T19:31:50.810973Z",
     "iopub.status.busy": "2025-05-06T19:31:50.810569Z",
     "iopub.status.idle": "2025-05-06T19:31:50.922045Z",
     "shell.execute_reply": "2025-05-06T19:31:50.921120Z",
     "shell.execute_reply.started": "2025-05-06T19:31:50.810941Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import evaluate\n",
    "from collections import defaultdict\n",
    "\n",
    "squad_metric = evaluate.load(\"squad\")\n",
    "\n",
    "from transformers import EvalPrediction\n",
    "cached_features = tokenized_datasets[\"validation\"]\n",
    "cached_raw_dataset = val_dataset\n",
    "\n",
    "\n",
    "def compute_metrics(eval_prediction):\n",
    "    start_logits, end_logits = eval_prediction.predictions\n",
    "    predictions = []\n",
    "    references = []\n",
    "\n",
    "    for i, feature in enumerate(cached_features):\n",
    "        offset_mapping = feature[\"offset_mapping\"]\n",
    "        context = cached_raw_dataset[i][\"context\"]\n",
    "        answer = cached_raw_dataset[i][\"answer\"]\n",
    "        answer_start = cached_raw_dataset[i][\"answer_start\"]\n",
    "\n",
    "        start_idx = int(np.argmax(start_logits[i]))\n",
    "        end_idx = int(np.argmax(end_logits[i]))\n",
    "\n",
    "        if (\n",
    "            start_idx >= len(offset_mapping)\n",
    "            or end_idx >= len(offset_mapping)\n",
    "            or offset_mapping[start_idx] is None\n",
    "            or offset_mapping[end_idx] is None\n",
    "            or end_idx < start_idx\n",
    "        ):\n",
    "            pred_text = \"\"\n",
    "        else:\n",
    "            start_char = offset_mapping[start_idx][0]\n",
    "            end_char = offset_mapping[end_idx][1]\n",
    "            pred_text = context[start_char:end_char]\n",
    "\n",
    "        predictions.append({\"id\": feature[\"example_id\"], \"prediction_text\": pred_text})\n",
    "        references.append({\n",
    "            \"id\": feature[\"example_id\"],\n",
    "            \"answers\": {\n",
    "                \"text\": [answer],\n",
    "                \"answer_start\": [answer_start]\n",
    "            }\n",
    "        })\n",
    "\n",
    "    return squad_metric.compute(predictions=predictions, references=references)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ca25caf4-72af-431d-ac4c-17c2f6dc2c19",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-06T19:31:51.544717Z",
     "iopub.status.busy": "2025-05-06T19:31:51.544501Z",
     "iopub.status.idle": "2025-05-06T19:31:51.549031Z",
     "shell.execute_reply": "2025-05-06T19:31:51.548008Z",
     "shell.execute_reply.started": "2025-05-06T19:31:51.544702Z"
    }
   },
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "compute_metrics_with_data = partial(\n",
    "    compute_metrics,\n",
    "    features=validation_features,\n",
    "    raw_dataset=val_dataset\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "810bd7cf-3953-4364-88eb-7797292e6f13",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-06T19:31:52.309842Z",
     "iopub.status.busy": "2025-05-06T19:31:52.309451Z",
     "iopub.status.idle": "2025-05-06T19:31:52.317045Z",
     "shell.execute_reply": "2025-05-06T19:31:52.316083Z",
     "shell.execute_reply.started": "2025-05-06T19:31:52.309810Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'attention_mask', 'offset_mapping', 'start_positions', 'end_positions', 'example_id'],\n",
       "    num_rows: 2562\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets[\"validation\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "81ba8b87-3087-48e6-aae7-e92c359782f2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-06T19:31:53.696866Z",
     "iopub.status.busy": "2025-05-06T19:31:53.696476Z",
     "iopub.status.idle": "2025-05-06T19:31:53.814940Z",
     "shell.execute_reply": "2025-05-06T19:31:53.813568Z",
     "shell.execute_reply.started": "2025-05-06T19:31:53.696834Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/transformers/training_args.py:1611: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_1275719/1307781823.py:20: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"steps\",\n",
    "    learning_rate=3e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=4,\n",
    "    num_train_epochs=10,\n",
    "    weight_decay=0.01,\n",
    "    # save_strategy=\"steps\",\n",
    "    # load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    report_to=\"none\",\n",
    "    logging_strategy=\"epoch\",\n",
    "    eval_steps=20,\n",
    "    eval_accumulation_steps=5\n",
    ")\n",
    "\n",
    "# Create Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=default_data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0f4687ef-7f32-401e-aa52-1bad9a6dff82",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-06T19:31:54.757105Z",
     "iopub.status.busy": "2025-05-06T19:31:54.756527Z",
     "iopub.status.idle": "2025-05-06T19:51:35.838697Z",
     "shell.execute_reply": "2025-05-06T19:51:35.837336Z",
     "shell.execute_reply.started": "2025-05-06T19:31:54.757070Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='278' max='9080' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 278/9080 19:37 < 10:25:47, 0.23 it/s, Epoch 0.31/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Exact Match</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.958750</td>\n",
       "      <td>12.841530</td>\n",
       "      <td>43.877486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.732234</td>\n",
       "      <td>63.817330</td>\n",
       "      <td>74.692714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.247621</td>\n",
       "      <td>93.754879</td>\n",
       "      <td>96.297110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.099337</td>\n",
       "      <td>95.979703</td>\n",
       "      <td>97.106317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.048475</td>\n",
       "      <td>98.360656</td>\n",
       "      <td>99.268762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.034709</td>\n",
       "      <td>98.946136</td>\n",
       "      <td>99.461170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.015240</td>\n",
       "      <td>99.141296</td>\n",
       "      <td>99.687807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.011656</td>\n",
       "      <td>99.648712</td>\n",
       "      <td>99.816743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.011971</td>\n",
       "      <td>99.570648</td>\n",
       "      <td>99.748795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.006470</td>\n",
       "      <td>99.609680</td>\n",
       "      <td>99.925223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.003826</td>\n",
       "      <td>99.882904</td>\n",
       "      <td>99.934421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.007221</td>\n",
       "      <td>99.687744</td>\n",
       "      <td>99.848258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.003236</td>\n",
       "      <td>99.921936</td>\n",
       "      <td>99.934331</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/transformers/trainer.py:2245\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2243\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2244\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2245\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2246\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2247\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2248\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2249\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2250\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/transformers/trainer.py:2561\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2555\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[1;32m   2556\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_step(model, inputs, num_items_in_batch)\n\u001b[1;32m   2558\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2559\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2560\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[0;32m-> 2561\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misinf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtr_loss_step\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   2562\u001b[0m ):\n\u001b[1;32m   2563\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2564\u001b[0m     tr_loss \u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m+\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n\u001b[1;32m   2565\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c4c4340a-b2f8-413e-9420-c3dd12765e2c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-06T19:53:52.957762Z",
     "iopub.status.busy": "2025-05-06T19:53:52.957527Z",
     "iopub.status.idle": "2025-05-06T19:53:58.211228Z",
     "shell.execute_reply": "2025-05-06T19:53:58.210590Z",
     "shell.execute_reply.started": "2025-05-06T19:53:52.957745Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./qa_model_russian/tokenizer_config.json',\n",
       " './qa_model_russian/special_tokens_map.json',\n",
       " './qa_model_russian/sentencepiece.bpe.model',\n",
       " './qa_model_russian/added_tokens.json',\n",
       " './qa_model_russian/tokenizer.json')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(\"./qa_model_russian\")\n",
    "tokenizer.save_pretrained(\"./qa_model_russian\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b47568-16fd-4cff-9472-ba9594a27579",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d710bda3-633e-458c-a10c-232937bcf9f0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-06T20:37:50.179567Z",
     "iopub.status.busy": "2025-05-06T20:37:50.179332Z",
     "iopub.status.idle": "2025-05-06T20:37:51.142967Z",
     "shell.execute_reply": "2025-05-06T20:37:51.142367Z",
     "shell.execute_reply.started": "2025-05-06T20:37:50.179552Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Answer: –Ø–Ω–¥–µ–∫—Å (+4,7%), –°–±–µ—Ä (+2,8%) –∏ –¢-–¢–µ—Ö–Ω–æ–ª–æ–≥–∏–∏ (+3,1%), —Ç–æ –µ—Å—Ç—å –±–æ–ª—å—à–∞—è —á–∞—Å—Ç—å –∫—Ä–∞—Ç–∫–æ—Å—Ä–æ—á–Ω—ã—Ö —Ñ–∞–≤–æ—Ä–∏—Ç–æ–≤ –∞–Ω–∞–ª–∏—Ç–∏–∫–æ–≤ –ë–ö–°.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
    "import torch\n",
    "\n",
    "# Load model and tokenizer\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model_path = \"./qa_model_russian\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(model_path).to(device)\n",
    "\n",
    "# Question\n",
    "question = \"–Ø–Ω–¥–µ–∫—Å\"\n",
    "\n",
    "# Initial context text\n",
    "context = \"\"\"\n",
    "–í –ì–æ—Å–¥–µ–ø–µ –°–®–ê —Å–æ–æ–±—â–∏–ª–∏, —á—Ç–æ –í–∞—à–∏–Ω–≥—Ç–æ–Ω –æ—Ç–∫–∞–∑—ã–≤–∞–µ—Ç—Å—è –æ—Ç —Ä–æ–ª–∏ –ø–æ—Å—Ä–µ–¥–Ω–∏–∫–∞ –≤ –¥–∏–∞–ª–æ–≥–µ –º–µ–∂–¥—É –†–æ—Å—Å–∏–µ–π –∏ –£–∫—Ä–∞–∏–Ω–æ–π, –Ω–æ –±—É–¥–µ—Ç –ø—Ä–æ–¥–æ–ª–∂–∞—Ç—å —Ä–∞–±–æ—Ç–∞—Ç—å –Ω–∞–¥ –¥–æ—Å—Ç–∏–∂–µ–Ω–∏–µ–º –º–∏—Ä–∞, –æ–¥–Ω–∞–∫–æ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–µ —Å–∏—Ç—É–∞—Ü–∏–∏ –∑–∞–≤–∏—Å–∏—Ç –æ—Ç ¬´–∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö –¥–µ–π—Å—Ç–≤–∏–π¬ª —Å–æ —Å—Ç–æ—Ä–æ–Ω—ã –ú–æ—Å–∫–≤—ã –∏ –ö–∏–µ–≤–∞.  \n",
    "\n",
    "–ù–µ –¥–æ–±–∞–≤–ª—è–µ—Ç –∏ –ø–æ–∑–∏—Ç–∏–≤–∞ –¥–∏–Ω–∞–º–∏–∫–∞ —Ü–µ–Ω—ã –Ω–∞ –Ω–µ—Ñ—Ç—å. –ü–æ–ø—ã—Ç–∫–∏ —Ä–∞–∑–≤–∏—Ç—å –≤—á–µ—Ä–∞—à–Ω–∏–π –æ—Ç—Å–∫–æ–∫ –Ω–µ —Ä–µ–∞–ª–∏–∑–æ–≤–∞–ª–∏—Å—å, –∏ –∫–æ—Ç–∏—Ä–æ–≤–∫–∏ –æ–ø—É—Å—Ç–∏–ª–∏—Å—å –Ω–∏–∂–µ $61 –∑–∞ –±–∞—Ä—Ä–µ–ª—å.\n",
    "\n",
    "–ê–∫—Ü–∏–∏ –≥–∞–∑–æ–≤—ã—Ö –∫–æ–º–ø–∞–Ω–∏–π ‚Äî –ì–∞–∑–ø—Ä–æ–º–∞ –∏ –ù–û–í–ê–¢–≠–ö–∞ ‚Äî —Å–µ–≥–æ–¥–Ω—è —Å—Ä–µ–¥–∏ –∞—É—Ç—Å–∞–π–¥–µ—Ä–æ–≤. \n",
    "\n",
    "–ì–∞–∑–ø—Ä–æ–º –ø—Ä–µ–¥—Å—Ç–∞–≤–∏–ª –≤ —Å—Ä–µ–¥—É —Å–∏–ª—å–Ω—ã–µ —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∑–∞ 2024 –≥. –†–∞—Å—á–µ—Ç–Ω—ã–π –¥–∏–≤–∏–¥–µ–Ω–¥ 30,3 —Ä—É–±. –ì–ª–∞–≤–Ω—ã–π –≤–æ–ø—Ä–æ—Å ‚Äî –≤–µ—Ä–Ω–µ—Ç—Å—è –ª–∏ –∫–æ—Ä–ø–æ—Ä–∞—Ü–∏—è –∫ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—é –ø—Ä–∏–±—ã–ª–∏ –≤–ø–µ—Ä–≤—ã–µ —Å 2022 –≥. –í—ã–ø–ª–∞—Ç—ã –Ω–µ –∑–∞–ª–æ–∂–µ–Ω—ã –≤ –±—é–¥–∂–µ—Ç, —á—Ç–æ –¥–æ–±–∞–≤–ª—è–µ—Ç –Ω–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ—Å—Ç–∏ –≤–∫—É–ø–µ –∫ –≥–µ–æ–ø–æ–ª–∏—Ç–∏—á–µ—Å–∫–æ–π –ø–æ–≤–µ—Å—Ç–∫–µ –≤ —Ü–µ–ª–æ–º.  \n",
    "\n",
    "–ë—É–º–∞–≥–∏ –ù–û–í–ê–¢–≠–ö–∞ –Ω–µ—Å—É—Ç –ø–æ—Ç–µ—Ä–∏ —á–µ—Ç–≤–µ—Ä—Ç—ã–π –¥–µ–Ω—å –ø–æ–¥—Ä—è–¥. –ë–ª–∏–∂–∞–π—à–∞—è –ø–æ–¥–¥–µ—Ä–∂–∫–∞ ‚Äî 200-–¥–Ω–µ–≤–Ω–∞—è —Å–∫–æ–ª—å–∑—è—â–∞—è —Å—Ä–µ–¥–Ω—è—è –Ω–∞ 1121 —Ä—É–±. –ö—Ä–æ–º–µ –æ–±—â–µ—Ä—ã–Ω–æ—á–Ω–æ–≥–æ –ø–µ—Å—Å–∏–º–∏–∑–º–∞, –¥–∞–≤–ª–µ–Ω–∏–µ –æ–∫–∞–∑—ã–≤–∞–µ—Ç –∏ —Å–Ω–∏–∂–µ–Ω–∏–µ —Ü–µ–Ω –Ω–∞ –Ω–µ—Ñ—Ç—å. –§–∏–Ω–∞–Ω—Å–æ–≤—ã–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏ –∫–æ–º–ø–∞–Ω–∏–∏ –∑–∞–≤–∏—Å—è—Ç, –≤ —á–∞—Å—Ç–Ω–æ—Å—Ç–∏, –æ—Ç —Ü–µ–Ω –Ω–∞ —á–µ—Ä–Ω–æ–µ –∑–æ–ª–æ—Ç–æ (–∫–æ–º–ø–∞–Ω–∏—è –ø—Ä–æ–¥–∞–µ—Ç –ø—Ä–æ–¥—É–∫—Ç—ã –ø–µ—Ä–µ—Ä–∞–±–æ—Ç–∫–∏ –≥–∞–∑–æ–≤–æ–≥–æ –∫–æ–Ω–¥–µ–Ω—Å–∞—Ç–∞, –∞ –¥–æ–ª–≥–æ—Å—Ä–æ—á–Ω—ã–µ –°–ü–ì-–∫–æ–Ω—Ç—Ä–∞–∫—Ç—ã –ø—Ä–∏–≤—è–∑–∞–Ω—ã –∫ –∫–æ—Ç–∏—Ä–æ–≤–∫–∞–º Brent).\n",
    "\n",
    "–ë—É–º–∞–≥–∏ –ü–æ–ª—é—Å–∞ –ø—ã—Ç–∞—é—Ç—Å—è –æ—Ç—Å–∫–æ—á–∏—Ç—å –ø–æ—Å–ª–µ —Å–µ–º–∏ –¥–Ω–µ–π –ø–∞–¥–µ–Ω–∏—è. –¶–µ–Ω—ã –Ω–∞ –∑–æ–ª–æ—Ç–æ –≤ –ø—è—Ç–Ω–∏—Ü—É –≤—ã—à–ª–∏ –≤ —É–º–µ—Ä–µ–Ω–Ω—ã–π –ø–ª—é—Å –ø–æ—Å–ª–µ –∫–æ—Ä—Ä–µ–∫—Ü–∏–æ–Ω–Ω–æ–≥–æ —Å–Ω–∏–∂–µ–Ω–∏—è –æ—Ç –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –º–∞–∫—Å–∏–º—É–º–æ–≤. –¢–∞–∫–∂–µ –ø–æ–¥–¥–µ—Ä–∂–∫—É –æ–∫–∞–∑—ã–≤–∞–µ—Ç –∏ —Ä–µ–∑–∫–æ–µ —Å–Ω–∏–∂–µ–Ω–∏–µ —Ä—É–±–ª—è. –î–ª—è –≤—ã—Ö–æ–¥–∞ –Ω–∞ —É–≤–µ—Ä–µ–Ω–Ω—É—é —Ç—Ä–∞–µ–∫—Ç–æ—Ä–∏—é —Ä–æ—Å—Ç–∞ –Ω—É–∂–Ω–∞ –ø–æ–¥–¥–µ—Ä–∂–∫–∞ —Å–æ —Å—Ç–æ—Ä–æ–Ω—ã —Ü–µ–Ω –Ω–∞ –±–∞–∑–æ–≤—ã–π –∞–∫—Ç–∏–≤.\n",
    "\n",
    "–ê–∫—Ü–∏–∏ –í–¢–ë –≤–æ –≤—Ç–æ—Ä–æ–π –ø–æ–ª–æ–≤–∏–Ω–µ –¥–Ω—è —Å–æ–∫—Ä–∞—Ç–∏–ª–∏ –¥–Ω–µ–≤–Ω—ã–µ –ø–æ—Ç–µ—Ä–∏. –ü–æ–¥–¥–µ—Ä–∂–∫—É –±—É–º–∞–≥–∞–º –æ–∫–∞–∑—ã–≤–∞–µ—Ç –¥–∏–≤–∏–¥–µ–Ω–¥–Ω—ã–π —Ñ–∞–∫—Ç–æ—Ä. –ù–∞–±—Å–æ–≤–µ—Ç –±–∞–Ω–∫–∞ —Ä–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–ª –≤—ã–ø–ª–∞—Ç–∏—Ç—å –¥–∏–≤–∏–¥–µ–Ω–¥—ã –∑–∞ 2024 –≥. –≤ —Ä–∞–∑–º–µ—Ä–µ 25,58 —Ä—É–±. –Ω–∞ –æ–¥–Ω—É –∞–∫—Ü–∏—é. –¢–µ–∫—É—â–∞—è –¥–∏–≤–∏–¥–µ–Ω–¥–Ω–∞—è –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—å ‚Äî –æ–∫–æ–ª–æ 26,3%. ¬´–î–∏–≤–∏–¥–µ–Ω–¥–Ω—ã–π —Å—é—Ä–ø—Ä–∏–∑¬ª —Å—Ç–∞–ª –¥—Ä–∞–π–≤–µ—Ä–æ–º —Ä–æ—Å—Ç–∞ –±—É–º–∞–≥ –≤ –ø–æ–Ω–µ–¥–µ–ª—å–Ω–∏–∫. –°–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –æ–ø—Ç–∏–º–∏–∑–º –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –ø—Ä–æ–≤–µ–¥–µ–Ω–∏—è –¥–æ–ø—ç–º–∏—Å—Å–∏–∏ –¥–ª—è –ø–æ–ø–æ–ª–Ω–µ–Ω–∏—è –∫–∞–ø–∏—Ç–∞–ª–∞, –Ω–æ –µ–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –ø–æ–∫–∞ –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω—ã.\n",
    "\n",
    "–ü—Ä–µ—Ñ—ã –¢—Ä–∞–Ω—Å–Ω–µ—Ñ—Ç–∏ —Å–º–æ—Ç—Ä—è—Ç—Å—è —Å–∏–ª—å–Ω–µ–µ –∫–æ–ª–ª–µ–≥ –ø–æ —Å–µ–∫—Ç–æ—Ä—É. –ó–¥–µ—Å—å —Ç–æ–∂–µ –≤ —Ñ–æ–∫—É—Å–µ –¥–∏–≤–∏–¥–µ–Ω–¥—ã –∑–∞ 2024 –≥. –ü–æ—Å–ª–µ –≤—ã—Ö–æ–¥–∞ –æ—Ç—á–µ—Ç–∞ –∑–∞ –ø—Ä–æ—à–ª—ã–π –≥–æ–¥, –º—ã –æ—Ü–µ–Ω–∏–≤–∞–µ–º –∏—Ö —Ä–∞–∑–º–µ—Ä –≤ 190 —Ä—É–±. –Ω–∞ –∞–∫—Ü–∏—é (–¥–∏–≤–∏–¥–µ–Ω–¥–Ω–∞—è –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—å 15%). –ö—Ä–æ–º–µ —Ç–æ–≥–æ, –¥–æ—Ö–æ–¥—ã –∫–æ–º–ø–∞–Ω–∏–∏ –Ω–µ –∑–∞–≤–∏—Å—è—Ç –æ—Ç —Ü–µ–Ω–æ–≤–æ–π –∫–æ–Ω—ä—é–Ω–∫—Ç—É—Ä—ã –Ω–∞ —Ä—ã–Ω–∫–µ –Ω–µ—Ñ—Ç–∏, –≥–¥–µ –±–∞—Ä—Ä–µ–ª—å Brent –∑–∞ –º–µ—Å—è—Ü –ø–æ–¥–µ—à–µ–≤–µ–ª –Ω–∞ 15%.\n",
    "\n",
    "–û–±—ã—á–∫–∞ –ë–°–ü ‚Äî –≤ –Ω–µ–±–æ–ª—å—à–æ–º –º–∏–Ω—É—Å–µ –∏ —Å–º–æ—Ç—Ä–∏—Ç—Å—è –ª—É—á—à–µ –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–∞ –ø—Ä–µ–¥—Å—Ç–∞–≤–∏—Ç–µ–ª–µ–π –ò–Ω–¥–µ–∫—Å–∞ –ú–æ—Å–ë–∏—Ä–∂–∏. –ê–∫—Ü–∏–∏ –Ω–∞ —Ç–µ–∫—É—â–µ–π –Ω–µ–¥–µ–ª–µ –ø–µ—Ä–µ–ø–∏—Å–∞–ª–∏ —Å–≤–æ–∏ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ –º–∞–∫—Å–∏–º—É–º—ã ‚Äî —Ç–µ–ø–µ—Ä—å —ç—Ç–æ 416,97 —Ä—É–±., –Ω–æ —É–∂–µ –≤ –ø–æ–Ω–µ–¥–µ–ª—å–Ω–∏–∫ –∂–¥–µ–º —Å–µ—Ä—å–µ–∑–Ω–æ–≥–æ –ø–∞–¥–µ–Ω–∏—è. –ü—Ä–∏—á–∏–Ω–∞ ‚Äî –±—É–º–∞–≥–∏ 5 –º–∞—è –æ—á–∏—Å—Ç—è—Ç—Å—è –æ—Ç —Ñ–∏–Ω–∞–ª—å–Ω—ã—Ö –¥–∏–≤–∏–¥–µ–Ω–¥–æ–≤ –∑–∞ 2024 –≥.  –í—ã–ø–ª–∞—Ç—ã —Å–æ—Å—Ç–∞–≤—è—Ç 29,72 —Ä—É–±. –Ω–∞ –æ–±—ã—á–∫—É, —á—Ç–æ –ø—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ—Ç —Ç–µ–∫—É—â—É—é –¥–∏–≤–∏–¥–µ–Ω–¥–Ω—É—é –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—å –Ω–∞ —É—Ä–æ–≤–Ω–µ 7,3%. –° —É—á–µ—Ç–æ–º –Ω–∞–ª–æ–≥–æ–≤ –Ω–∞ —Å—Ç–∞—Ä—Ç–µ —Å–ª–µ–¥—É—é—â–µ –Ω–µ–¥–µ–ª–µ –æ–Ω–∏ –º–æ–≥—É—Ç –ø–æ—Ç–µ—Ä—è—Ç—å 6,4%.\n",
    "\n",
    "–ê–∫—Ü–∏–∏ Nanduq (–±—ã–≤—à–∞—è Qiwi) —Å–µ–≥–æ–¥–Ω—è –ø–æ–¥—Å–∫–æ—á–∏–ª–∏ –Ω–∞ 21%. –ü–æ–≤–æ–¥–æ–º –¥–ª—è —Ä–µ–∑–∫–æ–≥–æ —Å–∫–∞—á–∫–∞ –≤–≤–µ—Ä—Ö –º–æ–≥–ª–æ —Å—Ç–∞—Ç—å —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –ª–∏–∫–≤–∏–¥–∞—Ç–æ—Ä–∞ –ö–∏–≤–∏-–ë–∞–Ω–∫–∞ –∞–∫—Ü–∏–æ–Ω–µ—Ä–∞–º –æ –Ω–∞–ª–∏—á–∏–∏ –∏ –ø—Ä–∞–≤–µ –∞–∫—Ü–∏–æ–Ω–µ—Ä–æ–≤ –Ω–∞ –ø–æ–ª—É—á–µ–Ω–∏–µ –∏–º—É—â–µ—Å—Ç–≤–∞, –æ—Å—Ç–∞–≤—à–µ–≥–æ—Å—è –ø–æ—Å–ª–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è —Ä–∞—Å—á–µ—Ç–æ–≤ —Å –∫—Ä–µ–¥–∏—Ç–æ—Ä–∞–º–∏.\n",
    "\"\"\"\n",
    "\n",
    "context = \"\"\"\n",
    "–ì–ª–∞–≤–Ω–æ–µ\n",
    "‚Ä¢ –ò–Ω–¥–µ–∫—Å –ú–æ—Å–ë–∏—Ä–∂–∏ –≤—ã—Ä–æ—Å –ø–æ—á—Ç–∏ –Ω–∞ 3% –≤–æ –≤—Ç–æ—Ä–Ω–∏–∫ –ø–æ—Å–ª–µ –ø—è—Ç–∏–¥–Ω–µ–≤–Ω–æ–≥–æ —Å–Ω–∏–∂–µ–Ω–∏—è.\n",
    "\n",
    "‚Ä¢ –¶–µ–Ω—ã –Ω–∞ –Ω–µ—Ñ—Ç—å –≤—á–µ—Ä–∞ –ø—Ä–æ–≤–æ—Ü–∏—Ä–æ–≤–∞–ª–∏ –ø—Ä–æ–¥–∞–∂–∏, –∞ —Å–µ–≥–æ–¥–Ω—è –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç –ø–æ–∫—É–ø–∞—Ç–µ–ª–µ–π, –ø—Ä–∏–±–∞–≤–ª—è—è 4%.\n",
    "\n",
    "‚Ä¢ –ê–∫—Ü–∏–∏ –ì–∞–∑–ø—Ä–æ–º–∞ –≤ —Ñ–æ–∫—É—Å–µ.\n",
    "\n",
    "‚Ä¢ –õ–∏–¥–µ—Ä—ã: –†–æ—Å—Å–µ—Ç–∏ –°–µ–≤–µ—Ä–æ-–ó–∞–ø–∞–¥ (+7,5%), –ë–°–ü-–∞–ø (+3,8%), –ü–ò–ö (+5,2%), –†—É—Å—Å–Ω–µ—Ñ—Ç—å (+5%).\n",
    "\n",
    "‚Ä¢ –ê—É—Ç—Å–∞–π–¥–µ—Ä—ã: NanduQ (-1,4%), –ë–∞—à–Ω–µ—Ñ—Ç—å-–∞–æ (-0,8%), –†–æ—Å—Å–µ—Ç–∏ –£—Ä–∞–ª (-0,3%), –í–ò.—Ä—É (-0,2%).\n",
    "\n",
    "–í –¥–µ—Ç–∞–ª—è—Ö\n",
    "–†—ã–Ω–æ–∫ –∞–∫—Ü–∏–π —Å–µ–≥–æ–¥–Ω—è –≤–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç—Å—è –ø–æ—Å–ª–µ 10%-–æ–≥–æ —Å–Ω–∏–∂–µ–Ω–∏—è –æ—Ç –º–∞–∫—Å–∏–º—É–º–æ–≤ –∞–ø—Ä–µ–ª—è. –í–Ω—É—à–∏—Ç–µ–ª—å–Ω—ã–π –æ—Ç—Å–∫–æ–∫, –∫–æ—Ç–æ—Ä—ã–π –ø–µ—Ä–µ–∫—Ä—ã–≤–∞–µ—Ç –≤—Å—é –ø—Ä–æ—Å–∞–¥–∫—É –ø–æ–Ω–µ–¥–µ–ª—å–Ω–∏–∫–∞ –≤—ã–≥–ª—è–¥–∏—Ç –ø–æ–∑–∏—Ç–∏–≤–Ω–æ, —Ö–æ—Ç—è –¥–æ –ø–æ–¥–¥–µ—Ä–∂–∫–∏ —Ä–∞—Å—Ç—É—â–µ–≥–æ —Ç—Ä–µ–Ω–¥–∞ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö –º–µ—Å—è—Ü–µ–≤ –≤ —Ä–∞–π–æ–Ω–µ 2650 –∏–Ω–¥–µ–∫—Å –Ω–µ –¥–æ—à–µ–ª. \n",
    "\n",
    "–ü—Ä–∏ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –∞–∫—Ç–∏–≤–Ω–æ–º –¥–≤–∏–∂–µ–Ω–∏–∏ –æ–±–æ—Ä–æ—Ç—ã –ª–∏—à—å –ø—Ä–∏–±–ª–∏–∂–∞—é—Ç—Å—è –∫ —Å—Ä–µ–¥–Ω–∏–º ‚Äî —Å–∫–∞–∑—ã–≤–∞–µ—Ç—Å—è —Ç–æ—Ä–≥–æ–≤—ã–π –ø–µ—Ä–∏–æ–¥ –º–µ–∂–¥—É –¥–ª–∏–Ω–Ω—ã–º–∏ –≤—ã—Ö–æ–¥–Ω—ã–º–∏. –í —Å–æ—Å—Ç–∞–≤–µ –∏–Ω–¥–µ–∫—Å–∞ –Ω–∞—Ç–æ—Ä–≥–æ–≤–∞–ª–∏ –Ω–∞ 82 –º–ª—Ä–¥ —Ä—É–±. \n",
    "\n",
    "–ù–∏–∫—É–¥–∞ –Ω–µ –∏—Å—á–µ–∑–ª–∏ –∏ –≥–µ–æ–ø–æ–ª–∏—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–∏—á–∏–Ω—ã —Å–¥–µ—Ä–∂–∏–≤–∞—é—â–∏–µ –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å. –ê–≥–µ–Ω—Ç—Å—Ç–≤–æ Reuters —Å–æ–æ–±—â–∏–ª–æ, —á—Ç–æ –ï–° –ø—Ä–µ–¥–ª–∞–≥–∞–µ—Ç –≤–∫–ª—é—á–∏—Ç—å –≤ 17-–π –ø–∞–∫–µ—Ç —Å–∞–Ω–∫—Ü–∏–π –ø—Ä–æ—Ç–∏–≤ –†–æ—Å—Å–∏–∏ –±–æ–ª–µ–µ 100 —Å—É–¥–æ–≤, —Å–≤—è–∑–∞–Ω–Ω—ã—Ö —Å —Ä–æ—Å—Å–∏–π—Å–∫–∏–º ¬´—Ç–µ–Ω–µ–≤—ã–º —Ñ–ª–æ—Ç–æ–º¬ª, –∏ –µ—â–µ 60 —Ñ–∏–∑–ª–∏—Ü –∏ —é—Ä–ª–∏—Ü.\n",
    "\n",
    "–í–Ω–µ—à–Ω–∏–π —Ñ–æ–Ω –ø–æ–¥–¥–µ—Ä–∂–∞–ª –æ—Ç—Å–∫–æ–∫ —Ü–µ–Ω –Ω–∞ –Ω–µ—Ñ—Ç—å. –ö–æ—Ç–∏—Ä–æ–≤–∫–∏ Brent –≤—á–µ—Ä–∞ –æ–ø—É—Å–∫–∞–ª–∏—Å—å –Ω–∏–∂–µ $59 –∑–∞ –±–∞—Ä—Ä–µ–ª—å, –∞ —Å–µ–≥–æ–¥–Ω—è –≤–µ—Ä–Ω—É–ª–∏—Å—å –∫ $62,5. –ó–¥–µ—Å—å –º–æ–≥–ª–∏ —Å–∫–∞–∑–∞—Ç—å—Å—è –≤—ã—à–µ–Ω–∞–∑–≤–∞–Ω–Ω—ã–µ —É–≥—Ä–æ–∑—ã –ï–° –ø—Ä–æ—Ç–∏–≤ –†–§, –≤–æ–∑–≤—Ä–∞—â–µ–Ω–∏–µ –∫ —Ç–æ—Ä–≥–∞–º —Ç—Ä–µ–π–¥–µ—Ä–æ–≤ –∫—Ä—É–ø–Ω–µ–π—à–µ–≥–æ –∏–º–ø–æ—Ä—Ç–µ—Ä–∞ –Ω–µ—Ñ—Ç–∏ ‚Äî–ö–∏—Ç–∞—è –ø–æ—Å–ª–µ –¥–ª–∏–Ω–Ω—ã—Ö –≤—ã—Ö–æ–¥–Ω—ã—Ö, –±–∞–Ω–∞–ª—å–Ω—ã–π —Å–ø–µ–∫—É–ª—è—Ç–∏–≤–Ω—ã–π –æ—Ç—Å–∫–æ–∫.\n",
    "\n",
    "–ù–∞ –ø—Ä–æ—à–ª–æ–π –Ω–µ–¥–µ–ª–µ –≤ —Ñ–æ–∫—É—Å–µ –∏–Ω–≤–µ—Å—Ç–æ—Ä–æ–≤ –±—ã–ª–∏ –∞–∫—Ü–∏–∏ –ì–∞–∑–ø—Ä–æ–º–∞ –≤–≤–∏–¥—É –æ–∂–∏–¥–∞–≤—à–µ–≥–æ—Å—è –æ—Ç—á–µ—Ç–∞, –∫–æ—Ç–æ—Ä—ã–π –æ–∫–∞–∑–∞–ª—Å—è –Ω–µ–ø–ª–æ—Ö–∏–º, —Ö–æ—Ç—è –∞–Ω–∞–ª–∏—Ç–∏–∫–∏ —Å–¥–µ—Ä–∂–∞–Ω–Ω–æ –æ—Ü–µ–Ω–∏–≤–∞—é—Ç –ø–µ—Ä—Å–ø–µ–∫—Ç–∏–≤—ã –≤—ã—Å–æ–∫–∏—Ö –¥–∏–≤–∏–¥–µ–Ω–¥–æ–≤. –°–µ–≥–æ–¥–Ω—è –±—É–º–∞–≥–∞ –æ—Å—Ç–∞–µ—Ç—Å—è –Ω–∞ –ø–µ—Ä–≤–æ–π —Å—Ç—Ä–æ—á–∫–µ –ø–æ –æ–±–æ—Ä–æ—Ç–∞–º –Ω–∞ —Ñ–æ–Ω–µ —Ä—è–¥–∞ –Ω–æ–≤–æ—Å—Ç–µ–π.\n",
    "\n",
    "–í–æ-–ø–µ—Ä–≤—ã—Ö, –≤ –Ω–∞—á–∞–ª–µ –≤–µ—á–µ—Ä–Ω–µ–π —Å–µ—Å—Å–∏–∏ –≥–ª–∞–≤–∞ –ú–∏–Ω—Ñ–∏–Ω–∞ –ê–Ω—Ç–æ–Ω –°–∏–ª—É–∞–Ω–æ–≤ –ø–æ–¥—Ç–≤–µ—Ä–¥–∏–ª, —á—Ç–æ –≤ –±—é–¥–∂–µ—Ç 2025 –≥. –Ω–µ –∑–∞–ª–æ–∂–µ–Ω—ã –¥–∏–≤–∏–¥–µ–Ω–¥—ã –ì–∞–∑–ø—Ä–æ–º–∞. –ù–æ —Ç–∞–∫–∂–µ –æ–Ω –æ—Ç–º–µ—Ç–∏–ª, —á—Ç–æ –∑–∞–¥–µ–π—Å—Ç–≤–æ–≤–∞—Ç—å —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ –º–µ—Ä—ã, –≤ —Ç–æ–º —á–∏—Å–ª–µ –Ω–∞–ª–æ–≥–æ–≤—ã–µ, –¥–ª—è –ø–æ–≤—ã—à–µ–Ω–∏—è –¥–æ—Ö–æ–¥–æ–≤ –±—é–¥–∂–µ—Ç–∞ –≤ —ç—Ç–æ–º –≥–æ–¥—É –Ω–µ –ø–ª–∞–Ω–∏—Ä—É–µ—Ç—Å—è. –û—Ç–∫–∞—Ç –Ω–∞ —ç—Ç–∏—Ö –Ω–æ–≤–æ—Å—Ç—è—Ö –±—ã–ª —Å–∫–æ—Ä–æ—Ç–µ—á–Ω—ã–º. \n",
    "\n",
    "–í–æ –≤—Ç–æ—Ä—ã—Ö, –ï–≤—Ä–æ–∫–æ–º–∏—Å—Å–∏—è –ø—Ä–µ–¥—Å—Ç–∞–≤–∏–ª–∞ ¬´–¥–æ—Ä–æ–∂–Ω—É—é –∫–∞—Ä—Ç—É¬ª –æ—Ç–∫–∞–∑–∞ –æ—Ç —Ä–æ—Å—Å–∏–π—Å–∫–∏—Ö —ç–Ω–µ—Ä–≥–æ—Ä–µ—Å—É—Ä—Å–æ–≤, –Ω–æ –∏ —ç—Ç–æ –Ω–µ —Å–∏–ª—å–Ω–æ —Ä–∞—Å—Å—Ç—Ä–æ–∏–ª–æ –∏–Ω–≤–µ—Å—Ç–æ—Ä–æ–≤, —Å —É—á–µ—Ç–æ–º —Ç–æ–≥–æ, —á—Ç–æ –ï–° –µ—â–µ –≤ 2022 –≥. –æ–∑–≤—É—á–∏–ª –ø–æ–¥–æ–±–Ω—ã–µ –ø–ª–∞–Ω—ã. –í —Ç–æ –∂–µ –≤—Ä–µ–º—è, –ø–æ–º–æ—â–Ω–∏–∫ –ø—Ä–µ–∑–∏–¥–µ–Ω—Ç–∞ –†–§ –Æ—Ä–∏–π –£—à–∞–∫–æ–≤ –∑–∞—è–≤–∏–ª, —á—Ç–æ –ø—Ä–µ–∑–∏–¥–µ–Ω—Ç –†–§ –í–ª–∞–¥–∏–º–∏—Ä –ü—É—Ç–∏–Ω –∏ –ø—Ä–µ–¥—Å–µ–¥–∞—Ç–µ–ª—å –ö–ù–† –°–∏ –¶–∑–∏–Ω—å–ø–∏–Ω 8 –º–∞—è –æ–±—Å—É–¥—è—Ç —à–∏—Ä–æ–∫–∏–π –∫—Ä—É–≥ –≤–æ–ø—Ä–æ—Å–æ–≤, –≤–∫–ª—é—á–∞—è –∫–æ–Ω—Ñ–ª–∏–∫—Ç –Ω–∞ –£–∫—Ä–∞–∏–Ω–µ, —ç–Ω–µ—Ä–≥–µ—Ç–∏–∫—É. –û—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ –ø–æ—Å–ª–µ–¥–Ω–µ–π –∏–Ω–≤–µ—Å—Ç–æ—Ä–æ–≤ –∏–Ω—Ç–µ—Ä–µ—Å—É–µ—Ç, –∫–æ–Ω–µ—á–Ω–æ, –≤–æ–ø—Ä–æ—Å ¬´–°–∏–ª—ã –°–∏–±–∏—Ä–∏-2¬ª. –ê–∫—Ü–∏–∏ –ì–∞–∑–ø—Ä–æ–º–∞ –≤—ã—Ä–æ—Å–ª–∏ –Ω–∞ 2,5% –Ω–∞ –æ—Å–Ω–æ–≤–Ω—ã—Ö —Ç–æ—Ä–≥–∞—Ö.\n",
    "\n",
    "–°—Ä–µ–¥–∏ –ª–∏–¥–µ—Ä–æ–≤ —Å–µ–≥–æ–¥–Ω—è –±—ã–ª–∏ –∞–∫—Ü–∏–∏ –ü–ò–ö, –°–∞–º–æ–ª–µ—Ç–∞, –í–ö, –°–∏—Å—Ç–µ–º—ã, —Ç–æ –µ—Å—Ç—å –∫–æ–º–ø–∞–Ω–∏–π —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω—ã—Ö –∫ –≤—ã—Å–æ–∫–∏–º –ø—Ä–æ—Ü–µ–Ω—Ç–Ω—ã–º —Å—Ç–∞–≤–∫–∞–º, –∫–æ—Ç–æ—Ä—ã–µ –∏ –ø–∞–¥–∞–ª–∏ —Å –æ–ø–µ—Ä–µ–∂–µ–Ω–∏–µ–º. –û—Ç–¥–µ–ª—å–Ω–æ –∑–¥–µ—Å—å —Å—Ç–æ–∏—Ç —Å–∫–∞–∑–∞—Ç—å –æ –í–ö, –∞–∫—Ü–∏–æ–Ω–µ—Ä—ã –∫–æ—Ç–æ—Ä–æ–π –æ–¥–æ–±—Ä–∏–ª–∏ –¥–æ–ø—ç–º–∏—Å—Å–∏—é. –í–ö —Ç–∞–∫–∏–º –æ–±—Ä–∞–∑–æ–º –ø–ª–∞–Ω–∏—Ä—É–µ—Ç —Å–Ω–∏–∑–∏—Ç—å –¥–æ–ª–≥–æ–≤—É—é –Ω–∞–≥—Ä—É–∑–∫—É. –†–∞–∑–º–µ—Ä –≤—ã–ø—É—Å–∫–∞ ‚Äî –¥–æ 115 –º–ª—Ä–¥ —Ä—É–±. –¶–µ–Ω–∞ –∞–∫—Ü–∏–∏ –ø—Ä–∏ –¥–æ–ø—ç–º–∏—Å—Å–∏–∏ ‚Äî 324,9 —Ä—É–±., –Ω–∞ 33% –≤—ã—à–µ —Ç–µ–∫—É—â–µ–π. –ê–Ω–∞–ª–∏—Ç–∏–∫–∏ –ë–ö–° —É—á–ª–∏ –≤ —Å–≤–æ–µ–π –º–æ–¥–µ–ª–∏ –¥–æ–ø—ç–º–∏—Å—Å–∏—é –∏ —Å–æ—Ö—Ä–∞–Ω—è—é—Ç –Ω–µ–π—Ç—Ä–∞–ª—å–Ω—ã–π –≤–∑–≥–ª—è–¥ –Ω–∞ –±—É–º–∞–≥—É —Å —Ü–µ–ª–µ–≤–æ–π —Ü–µ–Ω–æ–π 300 —Ä—É–±.\n",
    "\n",
    "–ù–µ—Å–º–æ—Ç—Ä—è –Ω–∞ –æ—Ç—Å–∫–æ–∫ —Ü–µ–Ω –Ω–∞ –Ω–µ—Ñ—Ç—å, –±–æ–ª–µ–µ —Å–∏–ª—å–Ω—É—é –¥–∏–Ω–∞–º–∏–∫—É —Å–µ–≥–æ–¥–Ω—è –ø–æ–∫–∞–∑–∞–ª–∏ –Ω–µ –†–æ—Å–Ω–µ—Ñ—Ç—å (+1,9%), –õ–£–ö–û–ô–õ (+1,4%) –∏ –¢–∞—Ç–Ω–µ—Ñ—Ç—å (+1,3%), –∞ –Ø–Ω–¥–µ–∫—Å (+4,7%), –°–±–µ—Ä (+2,8%) –∏ –¢-–¢–µ—Ö–Ω–æ–ª–æ–≥–∏–∏ (+3,1%), —Ç–æ –µ—Å—Ç—å –±–æ–ª—å—à–∞—è —á–∞—Å—Ç—å –∫—Ä–∞—Ç–∫–æ—Å—Ä–æ—á–Ω—ã—Ö —Ñ–∞–≤–æ—Ä–∏—Ç–æ–≤ –∞–Ω–∞–ª–∏—Ç–∏–∫–æ–≤ –ë–ö–°.\n",
    "\n",
    "–û–±–æ—Å–Ω–æ–≤–∞–Ω–Ω—ã–π —Ä–æ—Å—Ç –ø—Ä–æ–¥–æ–ª–∂–∞–µ—Ç—Å—è –≤ –∞–∫—Ü–∏—è—Ö –ü–æ–ª—é—Å–∞. –ö–æ—Ç–∏—Ä–æ–≤–∫–∏ –∑–æ–ª–æ—Ç–∞ —Å–º–æ–≥–ª–∏ –≤—á–µ—Ä–∞ –æ—Ç—Å–∫–æ—á–∏—Ç—å –æ—Ç –º–∏–Ω–∏–º—É–º–æ–≤ —Å —Å–µ—Ä–µ–¥–∏–Ω—ã –∞–ø—Ä–µ–ª—è –∏ —É–∂–µ –ø—Ä–µ–≤—ã—Å–∏–ª–∏ –æ—Ç–º–µ—Ç–∫—É $3400. \n",
    "\n",
    "–ù–µ—Å–∫–æ–ª—å–∫–æ –Ω–∞—Å—Ç–æ—Ä–∞–∂–∏–≤–∞–µ—Ç, —á—Ç–æ —Å–µ–≥–æ–¥–Ω—è—à–Ω–∏–π –æ–ø—Ç–∏–º–∏–∑–º –Ω–∞ —Ä—ã–Ω–∫–µ –∞–∫—Ü–∏–π –Ω–µ –±—ã–ª –ø–æ–¥–¥–µ—Ä–∂–∞–Ω —Å—Ç–æ–ª—å–∫–æ –∂–µ –∞–∫—Ç–∏–≤–Ω–æ–π –¥–∏–Ω–∞–º–∏–∫–æ–π –û–§–ó. RGBI –ø—Ä–∏–±–∞–≤–∏–ª –ª–∏—à—å 0,06%. –ó–∞–≤—Ç—Ä–∞ –ú–∏–Ω—Ñ–∏–Ω –ø—Ä–æ–≤–µ–¥–µ—Ç –∞—É–∫—Ü–∏–æ–Ω –ø–æ —Ä–∞–∑–º–µ—â–µ–Ω–∏—é –æ–±–ª–∏–≥–∞—Ü–∏–π 26233, –∞ –†–æ—Å—Å—Ç–∞—Ç –ø—Ä–µ–¥—Å—Ç–∞–≤–∏—Ç –¥–∞–Ω–Ω—ã–µ –ø–æ –Ω–µ–¥–µ–ª—å–Ω–æ–π –∏–Ω—Ñ–ª—è—Ü–∏–∏.\n",
    "\n",
    "–†—É–±–ª—å –ø–æ–∫–∞ –ø–æ-–ø—Ä–µ–∂–Ω–µ–º—É –Ω–µ —Å–ø–µ—à–∏—Ç —Å–Ω–∏–∂–∞—Ç—å—Å—è. –û—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã–π –∫—É—Ä—Å –¥–æ–ª–ª–∞—Ä–∞ –æ–ø—É—Å—Ç–∏–ª—Å—è –Ω–∏–∂–µ 81.\n",
    "\"\"\"\n",
    "\n",
    "# Split the context by newlines into paragraphs\n",
    "paragraphs = context.strip().split(\"\\n\")\n",
    "\n",
    "# Run QA on each paragraph and select the best\n",
    "best_answer = \"\"\n",
    "best_score = float('-inf')\n",
    "\n",
    "for paragraph in paragraphs:\n",
    "    inputs = tokenizer(question, paragraph, return_tensors=\"pt\", truncation=True).to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "    start_scores = outputs.start_logits\n",
    "    end_scores = outputs.end_logits\n",
    "\n",
    "    start_idx = torch.argmax(start_scores)\n",
    "    end_idx = torch.argmax(end_scores) + 1\n",
    "\n",
    "    answer_tokens = inputs[\"input_ids\"][0][start_idx:end_idx]\n",
    "    answer = tokenizer.decode(answer_tokens, skip_special_tokens=True)\n",
    "\n",
    "    score = start_scores[0][start_idx] + end_scores[0][end_idx - 1]\n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_answer = answer\n",
    "\n",
    "print(f\"Best Answer: {best_answer}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ddee70b-7f43-4fce-889e-ecf73f170adf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
